{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer in Keras.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ummeamunira/Digit-recognizer-tensorflow/blob/master/Digit_Recognizer_in_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Build your first neural network in Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FbVhjPpzn6BM"
      },
      "source": [
        "When it comes to talk in AI language, deep learning and neural network are used almost interchangeably. For this article, I am assuming all my readers have basic knowledge on neural network and how it works. One of the popular datasets for deep learning is MNIST dataset; images of hand-written digits to identify the digit from handwritten digit's images.\n",
        "This can be the first neural network where novice deep learners can start.\n",
        "\n",
        "In this article, I have used [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v5cHbq_G5_e",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV2EAL40bZMH",
        "colab_type": "text"
      },
      "source": [
        "Let's start with importing necessary libraries. Here, I have used Keras; the framework for defining a neural network as a set of Sequential layers in TensorFlow. So, first, I am importing TensorFlow and calling it as tf, then importing keras.\n",
        "\n",
        "As helper libraries, I am importing NumPy to represent our data as lists and matplotlib for data visualization.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2i5y0zJIioD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dzLKpmZICaWN",
        "colab": {}
      },
      "source": [
        "# TensorFlow and tf.keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import and Split the Dataset \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "Since this MNIST dataset is already available in tf.keras datasets API, we can directly load it from there. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7MqDQO0KCaWS",
        "colab": {}
      },
      "source": [
        "mnist = keras.datasets.mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0TFqdW0saZK",
        "colab_type": "text"
      },
      "source": [
        "Next step is to split the data into training and test sets. load_data will give us training and test images and their related labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG7ZzB_mscJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "This will give us four different NumPy arrays;\n",
        "* `x_train` and `y_train`: dataset to train the model\n",
        "* `x_test` and `y_test`: dataset to test the model with these images \n",
        "\n",
        "Here, `x_train` and `x_test` are greyscale images (RGB codes from 0 to 255) stored as 28x28 NumPy array. `y_train` and `y_test` are labels for the number between 0 to 9."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "## Explore the data\n",
        "\n",
        "To explore, let's first see the format of the dataset. It shows that there are 60,000 images in the training set and each image is represented as 28 x 28 pixels. `len(y_train)` shows there are 60000 labels in the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zW5k_xz1CaWX",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TRFYHB2mCaWb",
        "colab": {}
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TMPI88iZpO2T"
      },
      "source": [
        "Let's try the same with test set. There are 10000 images in the test set. Like training data, each image is represented as 28 x 28 pixels and it contains 10000 image labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2KFnYlcwCaWl",
        "colab": {}
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJmPr5-ACaWn",
        "colab": {}
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o72m6biX2Rcv",
        "colab_type": "text"
      },
      "source": [
        "Let's print a training image, and a training label to see how does it look. Since it's 2020, I want to see what is the number at index=2020."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkhh9mJH2eL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x_train[2020])\n",
        "print(y_train[2020])\n",
        "print(x_train[2020])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIioJgf53q5h",
        "colab_type": "text"
      },
      "source": [
        "Well it's 6. However, you can see that the pixel values are in the range of 0 to 255. It is easier for us to normalize the data between 0 to 1 and we can do that just by diving our train and test set by 255."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bW5WzIPlCaWv",
        "colab": {}
      },
      "source": [
        "x_train = x_train / 255.0\n",
        "\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "Next step is to design the model. Neural network is mainly built by the layers by chaining them together. I have designed a simple neural network below with three layers. **Sequential** defines a sequence of layers in the neural network. First layer; `tf.keras.layers.Flatten` converts our two-dimensional arrays (28 by 28) into a 1 dimensional array (28 * 28 = 784). Next, we have two sequential layers; `tf.keras.layers.Dense`. First one has 128 neurons and the last one has 10 neuron which will return 10 probability scores as an array since we have 10 different labels (0,1,2,3,4,5,6,7,8 and 9) to identify the digits.\n",
        "\n",
        "I have also specified the activation functions here. **Activation function** instructs the neurons what to do. There are other options too. Just for now, I have used relu and softmax. You can play with [others](https://https://www.tensorflow.org/api_docs/python/tf/keras/activations) and can see the differences in result.\n",
        "\n",
        "**Relu** effectively means \"If X>0 return X, else return 0\"; it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "**Softmax** is often used as the activation for the last layer of a classification network because the result could be interpreted as a probability distribution.It takes a set of values, and effectively picks the biggest one. For example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it turns that into [0,0,0,0,1,0,0,0,0]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGCO3g4W6Zwu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "## Compile the model\n",
        "\n",
        "We have built our model. Now we have to compile it. Here, we have to specify a loss function and an optimizer.\n",
        "\n",
        "So, what does a loss function do? When neural netwrok try to learn, it makes a guess, i.e., it takes an input and guesses an output. Here comes the loss function to find out how correctly or incorrectly our network identifies the labels against our given correct labels. Then comes the optimizer; it tries to minimize the loss and makes another guess. Again, our loss function finds out how good or bad is the model output with respect to our given labels. Optimizer again optimizes to minimize the loss, gives another output. This chain usually keeps going until it reaches a certain number of iterations or level of accuracy (set by us). We will set this certain number of iterations with the `model.fit` code. Otherwise, if we want a certain level of accuracy (e.g. 85% or 95%), we can specify that by callback option.\n",
        "\n",
        "Now , here we will use sparse_categorical_crossentropy (computes the crossentropy loss between the labels and predictions) as loss function and 'adam' as optimizer. We will also specify the metrics as 'accuracy' to monitor the training and testing steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lhan11blCaW7",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Train the model\n",
        "Now we need to use `model.fit` function to train our model. This function will go through the loop; making a guess, measuring how good or bad it is, i.e., loss, using the opimizer to make another guess etc. It will do it for our specified number of epochs. All the epochs will be shown here with their related loss and accuracy. So, here, we are going to feed the training images with their labels to train the model. Our model will be trained using guesses and then it will make predictions with our test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xvwvpA64CaW_",
        "colab": {}
      },
      "source": [
        "model.fit(x_train, y_train, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "After making all the guesses, we should see an accuracy value at the end of last epoch. It should look like something 0.995 (or 99.5%) which means our neural network is about 99.5% accurate in classifying training images to its correct labels. This is great considering only 10 epochs and it was quick.\n",
        "\n",
        "But we do not know how would it work with unseen data? That's why we have the test images. We can call `model.evaluate`, and pass in the two sets, and it will report back the loss for each."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Evaluate accuracy\n",
        "\n",
        "Next, compare how the model performs on the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VflXLEeECaXC",
        "colab": {}
      },
      "source": [
        "model.evaluate(x_test,  y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "So, it is little less than the training set; 98%. Still good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## Make predictions\n",
        "Now, we have trained our model. Let's see our first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gl91RPhdCaXI",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)\n",
        "predictions[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "This prediction is an array of 10 numbers. They represent the model's \"confidence\" that the image corresponds to each of the 10 different digits. From the above array, we can tell that the eighth label has the highest prediction value (0.99) and that should be our digit (which is 'seven').\n",
        "Let's see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qsqenuPnCaXO",
        "colab": {}
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So, the model is most confident that this image is number **7**. Let's see what this image actually is by using our test label:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sd7Pgsu6CaXP",
        "colab": {}
      },
      "source": [
        "y_test[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Great!! Our neural net has successfully recognized our digit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGTpF22ZL5fl",
        "colab_type": "text"
      },
      "source": [
        "Thanks for reading. Hope you like this article."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHb-8obrK6xF",
        "colab_type": "text"
      },
      "source": [
        "### References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RbUJrYFGuoC",
        "colab_type": "text"
      },
      "source": [
        "1. Basic classification: Classify images of clothing\n",
        "(https://www.tensorflow.org/tutorials/keras/classification)"
      ]
    }
  ]
}